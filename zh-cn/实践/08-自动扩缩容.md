## 操作步骤

### 创建一个Deployment

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kubia
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v1
        name: nodejs
        resources:
          limits:
            cpu: "200m"
          requests:
            cpu: 100m
```
资源限制的具体配置可以查看[K8s官方文档](https://kubernetes.io/zh-cn/docs/reference/kubernetes-api/workload-resources/pod-v1/#Container)

### 创建一个HPA资源

```
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: kubia
spec:
  maxReplicas: 5
  minReplicas: 1
  targetCPUUtilizationPercentage: 30
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
```

* 最大副本数为5
* 最小副本数为1
* cpu利用率目标是30%
* HPA自动扩缩容的资源指定为kubia

#### 扩展

```
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: kubia
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 30
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 0
    scaleUp:
      stabilizationWindowSeconds: 0
```

- autoscaling/v2beta2提供更丰富的设置
- 在K8S 1.18及之后版本的autoscaling/v2beta2 API下,提供behavior设置,可以定制HPA的行为,比如拉取指标间隔时间、稳定窗口等
- 此处配置升级、降级稳定窗口时间为0,表示不防抖,检测到指标变化即可响应扩容、缩容
- stabilizationWindowSeconds默认设置为5分钟.如果5分钟内已经扩、缩容,那么这五分钟即使发生指标超高或降低,也不会扩、缩容,防止频繁扩、缩容
- 在K8S 1.18之前版本,只能通过设置kube-controller-manager启动参数设置

    - --horizontal-pod-autoscaler-sync-period: 抓取指标周期默认15秒
    - --horizontal-pod-autoscaler-downscale-stabilization: 缩容冷却时间。 即自从上次缩容执行结束后，多久可以再次执行缩容，默认时间是5分钟
    - horizontal-pod-autoscaler-upscale-stabilization: 用于指定自动扩容器必须等待多长时间才能完成当前操作后再执行另一次扩容操作。默认值为3分钟

### watch HPA资源监控CPU利用率变化

```
kubectl get hpa kubia --watch -n service
```

<p align="left"><img alt="" src="https://hsop-doc.fsh.bcebos.com/doc_classify/0/HSOP-BAIDU/38e1f14fbe964276ba2355bd2a0d28f9@image.png" width="auto" height="auto"></p>

### 观察kubia对应副本数变化

<p align="left"><img alt="" src="https://hsop-doc.fsh.bcebos.com/doc_classify/0/HSOP-BAIDU/f4583b8550064f6885d53c0ca34458aa@image.png" width="auto" height="auto"></p>

* HPA根据收集的指标,计算需要的扩缩容数据,对管理资源进行扩缩容
* 等待一段时间,发现kubia副本数从3降到了1.因为kubia管理的pod没有任何请求进入,cpu利用率为0.但我们现在了最小副本数为1,所以等待一段时间后副本数将为1

<p align="left"><img alt="" src="https://hsop-doc.fsh.bcebos.com/doc_classify/0/HSOP-BAIDU/a1e1f860fd374336ba35ec2f139e5ec6@image.png" width="auto" height="auto"></p>

### 创建service暴露kubia管理pod

<p align="left"><img alt="" src="https://hsop-doc.fsh.bcebos.com/doc_classify/0/HSOP-BAIDU/b8043f81657f4520864cace9c8ae0890@image.png" width="auto" height="auto"></p>

### 运行pod访问kubia增大CPU利用率

```
kubectl run -i --tty load-generator --rm --image=busybox:1.28 --namespace=service --restart=Never -- /bin/sh -c "while true; do wget -q -O- http://kubia-service; done"
```

### 观察kubia对应副本数变化

<p align="left"><img alt="" src="https://hsop-doc.fsh.bcebos.com/doc_classify/0/HSOP-BAIDU/04d34a6132b3437a8bc6032784c65a54@image (1).png" width="auto" height="auto"></p>

* 当启动无限循环,请求kubia pod,由于开始时只有一个pod响应请求,CPU迅速超过30%,HPA等一段时间后会重新计算需要的副本数,扩容,将CPU利用率降低到30%以下

### 停止pod访问kubia,观察kubia副本数变化

<p align="left"><img alt="" src="https://hsop-doc.fsh.bcebos.com/doc_classify/0/HSOP-BAIDU/6b46958342754d3786bae491f2e35ed7@image.png" width="auto" height="auto"></p>

* 当停止访问kubia后,kubia CPU利用率迅速降低到0,HPA会根据收集到的指标,计算需要的副本数,由于有最小副本数1的限制,kubia的副本数又会回落到1


#!/bin/bash
nodeDeployPackagePath=/data/jar/pkg
deployPackagePath=/tmp/cache/package/cicd-host-test3-main-hand-hzero-gateway
sshpass -p 5w2Sg2durdpqd7Br ssh -t -t root@172.23.16.219 -p 22 "rm -rf ${deployPackagePath};mkdir -p ${deployPackagePath};exit"
sshpass -p 5w2Sg2durdpqd7Br scp -P 22 target/hand-hzero-gateway-2023.07.07-113620-develop.jar root@172.23.16.219:${deployPackagePath}/hand-hzero-gateway-2023.07.07-113620-develop.jar
packageName=hand-hzero-gateway-2023.07.07-113620-develop.jar
deployNodes=`curl -k -X GET --header "Content-Type: application/json" --header "Accept: */*" "http://172.23.17.104:31300/v1/node-clusters/instance-node?clusterCode=1af81017-f738-4c96-ba07-b51fb656ea0c&envCode=cicd-host-test3&instanceCode=cicd-host-test3-main-hand-hzero-gateway"`
for k in $(jq keys
.[] <<< "${deployNodes}"); do
deployNode=$(jq -r ".[$k]" <<< "${deployNodes}");
deployHostIp=$(jq -r .hostIp <<< "${deployNode}");
deployNodePassword=$(jq -r .password <<< "${deployNode}");
deployNodeUsername=$(jq -r .userName <<< "${deployNode}");
deployHostPort=$(jq -r .hostPort <<< "${deployNode}");
sshpass -p 5w2Sg2durdpqd7Br ssh -t -t root@172.23.16.219 -p 22 "sshpass -p  scp -P ${deployHostPort} ${deployPackagePath}/${packageName} ${deployNodeUsername}@${deployHostIp}:${nodeDeployPackagePath}/${packageName};exit;"
done
/tmp/source/a634136b-0b24-4425-a7d3-ab32b863a2b7/hand-hzero-gateway@tmp/durable-53dafc3c/script.sh: 15: .[] <<< "${deployNodes}"); do
deployNode=$(jq -r ".[$k]" <<< "${deployNodes}");
deployHostIp=$(jq -r .hostIp <<< "${deployNode}");
deployNodePassword=$(jq -r .password <<< "${deployNode}");
deployNodeUsername=$(jq -r .userName <<< "${deployNode}");
deployHostPort=$(jq -r .hostPort <<< "${deployNode}");
sshpass -p 5w2Sg2durdpqd7Br ssh -t -t root@172.23.16.219 -p 22 "sshpass -p  scp -P ${deployHostPort} ${deployPackagePath}/${packageName} ${deployNodeUsername}@${deployHostIp}:${nodeDeployPackagePath}/${packageName};exit;"
done